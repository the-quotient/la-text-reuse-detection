{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4f72be-8b9e-46ec-b3be-c8b95e2a9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "\n",
    "def analyse_retriever(file):\n",
    "    # Load the data\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    model_data = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for entry in data:\n",
    "        model = entry[\"model\"]\n",
    "        for result in entry[\"results\"]:\n",
    "            key = (result[\"k\"], result[\"threshold\"])\n",
    "            metrics = {\n",
    "                \"recall@k\": result[\"recall@k\"],\n",
    "                \"false_positive_rate\": result[\"false_positive_rate\"],\n",
    "                \"precision@k\": result[\"precision@k\"],\n",
    "                \"f1@k\": result[\"f1@k\"]\n",
    "            }\n",
    "            model_data[model][key].append(metrics)\n",
    "    \n",
    "    # Average metrics across datasets\n",
    "    averaged_data = defaultdict(dict)\n",
    "    \n",
    "    for model, param_dict in model_data.items():\n",
    "        for (k, threshold), results in param_dict.items():\n",
    "            averaged_metrics = {\n",
    "                \"recall@k\": mean(r[\"recall@k\"] for r in results),\n",
    "                \"false_positive_rate\": mean(r[\"false_positive_rate\"] for r in results),\n",
    "                \"precision@k\": mean(r[\"precision@k\"] for r in results),\n",
    "                \"f1@k\": mean(r[\"f1@k\"] for r in results)\n",
    "            }\n",
    "            averaged_data[model][(k, threshold)] = averaged_metrics\n",
    "    \n",
    "    # Select best (k, threshold) per model with highest recall@k under fpr < 0.4\n",
    "    best_metrics = {}\n",
    "    \n",
    "    for model, metrics_dict in averaged_data.items():\n",
    "        best_combo = None\n",
    "        best_recall = -1\n",
    "        for (k, threshold), metrics in metrics_dict.items():\n",
    "            if metrics[\"false_positive_rate\"] < 0.4 and metrics[\"recall@k\"] > best_recall:\n",
    "                best_recall = metrics[\"recall@k\"]\n",
    "                best_combo = (k, threshold, metrics)\n",
    "        if best_combo:\n",
    "            best_metrics[model] = {\n",
    "                \"k\": best_combo[0],\n",
    "                \"threshold\": best_combo[1],\n",
    "                **best_combo[2]\n",
    "            }\n",
    "    \n",
    "    df_best = pd.DataFrame.from_dict(best_metrics, orient=\"index\").reset_index()\n",
    "    df_best.rename(columns={\"index\": \"model\"}, inplace=True)\n",
    "    \n",
    "    df_best[\"X\"] = df_best[\"model\"].str.extract(r'_(\\d+)_')\n",
    "    df_best[\"X\"] = pd.to_numeric(df_best[\"X\"], errors='coerce')\n",
    "    \n",
    "    df_best[\"SPhilBERTa_priority\"] = df_best[\"model\"].str.contains(\"SPhilBERTa\").astype(int)\n",
    "    df_best.sort_values(by=[\"SPhilBERTa_priority\", \"X\"], ascending=[False, True], inplace=True)\n",
    "    df_best.drop(columns=[\"SPhilBERTa_priority\", \"X\"], inplace=True)\n",
    "    \n",
    "    print(df_best.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "def analyse_reranker(file_path):\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Organize data: model -> threshold -> list of f1 scores\n",
    "    model_data = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for entry in data:\n",
    "        model = entry[\"model\"]\n",
    "        threshold = entry[\"threshold\"]\n",
    "        f1_score = entry[\"classification_report\"][\"1\"][\"f1-score\"]\n",
    "        model_data[model][threshold].append(f1_score)\n",
    "    \n",
    "    # Average metrics across datasets\n",
    "    averaged_data = defaultdict(dict)\n",
    "    for model, threshold_dict in model_data.items():\n",
    "        for threshold, scores in threshold_dict.items():\n",
    "            averaged_data[model][threshold] = mean(scores)\n",
    "    \n",
    "    # Select best threshold per model by highest average f1-score\n",
    "    best_metrics = {}\n",
    "    for model, scores_dict in averaged_data.items():\n",
    "        best_threshold = max(scores_dict, key=scores_dict.get)\n",
    "        best_metrics[model] = {\n",
    "            \"threshold\": best_threshold,\n",
    "            \"f1_score\": scores_dict[best_threshold]\n",
    "        }\n",
    "    \n",
    "    # Convert to DataFrame and sort\n",
    "    df_best = pd.DataFrame.from_dict(best_metrics, orient=\"index\").reset_index()\n",
    "    df_best.rename(columns={\"index\": \"model\"}, inplace=True)\n",
    "    \n",
    "    # Extract X from model string assuming format like 'Name_X_Y'\n",
    "    df_best[\"X\"] = df_best[\"model\"].str.extract(r'_(\\d+)_')\n",
    "    df_best[\"X\"] = pd.to_numeric(df_best[\"X\"], errors='coerce')\n",
    "\n",
    "\n",
    "    df_best.sort_values(by=\"X\", ascending=True, inplace=True)\n",
    "    df_best.drop(columns=[\"X\"], inplace=True)\n",
    "\n",
    "    print(df_best.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36914651-6486-4806-bcd2-73840e0f343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model  k  threshold  recall@k  false_positive_rate  precision@k     f1@k\n",
      "   SPhilBERTa  7       0.75     0.825             0.382490     0.623232 0.671670\n",
      "BEmargin_03_0  3       0.55     0.925             0.298156     0.728326 0.785846\n",
      "BEmargin_04_0  3       0.55     0.945             0.353088     0.715826 0.782504\n",
      "BEmargin_05_0  3       0.60     0.910             0.235920     0.744162 0.794176\n",
      "BEmargin_06_0  3       0.60     0.960             0.353892     0.750828 0.811674\n",
      "BEmargin_07_0  3       0.65     0.950             0.301316     0.786660 0.834178\n",
      "BEmargin_08_0  5       0.70     0.895             0.256860     0.746576 0.788342\n",
      "BEmargin_09_0  5       0.70     0.935             0.384044     0.699826 0.762672\n",
      "BEmargin_10_0  3       0.75     0.895             0.305568     0.734994 0.782510\n",
      "\n",
      "        model  k  threshold  recall@k  false_positive_rate  precision@k    f1@k\n",
      "   SPhilBERTa  3       0.75   0.55000              0.39740      0.47221 0.48555\n",
      "BEmargin_03_0  3       0.55   0.75000              0.29451      0.56389 0.62194\n",
      "BEmargin_04_0  3       0.55   0.83334              0.35678      0.63196 0.69528\n",
      "BEmargin_05_0  3       0.60   0.74167              0.24384      0.59861 0.62307\n",
      "BEmargin_06_0  3       0.60   0.90000              0.36016      0.63749 0.71751\n",
      "BEmargin_07_0  3       0.65   1.00000              0.30627      0.76250 0.83666\n",
      "BEmargin_08_0  3       0.70   0.80834              0.26093      0.64722 0.64722\n",
      "BEmargin_09_0  3       0.70   0.86667              0.38643      0.63194 0.69750\n",
      "BEmargin_10_0  3       0.75   0.79167              0.30095      0.61527 0.63334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_retriever(\"results/BE/eval_BE_S_Ge.json\")\n",
    "analyse_retriever(\"results/BE/eval_BE_M_Ge.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29d4b809-5722-473d-a580-ca7119c65955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         model  threshold  f1_score\n",
      "CEPweight_00_5        0.2  0.983918\n",
      "CEPweight_01_0        0.2  0.980650\n",
      "CEPweight_02_0        0.2  0.974802\n",
      "CEPweight_03_0        0.2  0.986550\n",
      "CEPweight_04_0        0.4  0.980994\n",
      "CEPweight_05_0        0.2  0.981287\n",
      "CEPweight_06_0        0.2  0.985913\n",
      "CEPweight_07_0        0.2  0.983918\n",
      "CEPweight_08_0        0.2  0.980650\n",
      "CEPweight_09_0        0.2  0.986550\n",
      "CEPweight_10_0        0.2  0.980994\n",
      "CEPweight_11_0        0.2  0.983918\n",
      "CEPweight_12_0        0.2  0.975439\n",
      "\n",
      "         model  threshold  f1_score\n",
      "CEPweight_00_5        0.2  0.947369\n",
      "CEPweight_01_0        0.2  0.941754\n",
      "CEPweight_02_0        0.3  0.949491\n",
      "CEPweight_03_0        0.4  0.948259\n",
      "CEPweight_04_0        0.3  0.945069\n",
      "CEPweight_05_0        0.6  0.950946\n",
      "CEPweight_06_0        0.2  0.953885\n",
      "CEPweight_07_0        0.2  0.943402\n",
      "CEPweight_08_0        0.2  0.944645\n",
      "CEPweight_09_0        0.2  0.952369\n",
      "CEPweight_10_0        0.8  0.951413\n",
      "CEPweight_11_0        0.2  0.949571\n",
      "CEPweight_12_0        0.2  0.939210\n",
      "\n",
      "         model  threshold  f1_score\n",
      "CEPweight_00_5        0.2  0.708333\n",
      "CEPweight_01_0        0.2  0.750000\n",
      "CEPweight_02_0        0.2  0.745098\n",
      "CEPweight_03_0        0.2  0.823529\n",
      "CEPweight_04_0        0.2  0.750000\n",
      "CEPweight_05_0        0.2  0.777778\n",
      "CEPweight_06_0        0.2  0.856209\n",
      "CEPweight_07_0        0.2  0.750000\n",
      "CEPweight_08_0        0.2  0.708333\n",
      "CEPweight_09_0        0.2  0.786765\n",
      "CEPweight_10_0        0.2  0.823529\n",
      "CEPweight_11_0        0.2  0.750000\n",
      "CEPweight_12_0        0.2  0.786765\n",
      "\n",
      "         model  threshold  f1_score\n",
      "CEPweight_00_5        0.2  0.708333\n",
      "CEPweight_01_0        0.2  0.750000\n",
      "CEPweight_02_0        0.2  0.701389\n",
      "CEPweight_03_0        0.2  0.823529\n",
      "CEPweight_04_0        0.2  0.727941\n",
      "CEPweight_05_0        0.2  0.777778\n",
      "CEPweight_06_0        0.3  0.856209\n",
      "CEPweight_07_0        0.2  0.727941\n",
      "CEPweight_08_0        0.2  0.708333\n",
      "CEPweight_09_0        0.2  0.741830\n",
      "CEPweight_10_0        0.2  0.823529\n",
      "CEPweight_11_0        0.2  0.750000\n",
      "CEPweight_12_0        0.2  0.764706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_reranker(\"results/CEP/EVAL-CEP-S1.json\")\n",
    "analyse_reranker(\"results/CEP/EVAL-CEP-S2.json\")\n",
    "analyse_reranker(\"results/CEP/EVAL-CEP-M1.json\")\n",
    "analyse_reranker(\"results/CEP/EVAL-CEP-M2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7adc538-de3d-4dec-82e6-348864489926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         model  threshold  f1_score\n",
      "CESweight_00_5        0.6  0.994987\n",
      "CESweight_01_0        0.7  0.997619\n",
      "CESweight_02_0        0.2  0.997619\n",
      "CESweight_03_0        0.2  0.997619\n",
      "CESweight_04_0        0.2  0.997619\n",
      "CESweight_05_0        0.2  0.997619\n",
      "CESweight_06_0        0.2  1.000000\n",
      "CESweight_07_0        0.2  0.997619\n",
      "CESweight_08_0        0.4  1.000000\n",
      "CESweight_09_0        0.2  0.997619\n",
      "CESweight_10_0        0.5  0.997619\n",
      "CESweight_11_0        0.4  0.992607\n",
      "CESweight_12_0        0.2  0.997619\n",
      "\n",
      "         model  threshold  f1_score\n",
      "CESweight_00_5        0.2  0.973684\n",
      "CESweight_01_0        0.2  0.973684\n",
      "CESweight_02_0        0.2  0.973684\n",
      "CESweight_03_0        0.2  1.000000\n",
      "CESweight_04_0        0.2  1.000000\n",
      "CESweight_05_0        0.2  0.947368\n",
      "CESweight_06_0        0.2  0.973684\n",
      "CESweight_07_0        0.2  0.976190\n",
      "CESweight_08_0        0.2  1.000000\n",
      "CESweight_09_0        0.2  1.000000\n",
      "CESweight_10_0        0.2  1.000000\n",
      "CESweight_11_0        0.2  0.973684\n",
      "CESweight_12_0        0.2  0.973684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_reranker(\"results/CES/EVAL-CES-S1.json\")\n",
    "analyse_reranker(\"results/CES/EVAL-CES-M1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37942f6-1139-4714-ba55-a3d6505a0ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
